import json
import os
import time
from copy import deepcopy
import xml.sax.saxutils
from typing import List, Dict, Any, Optional, Generator, Union

from rich.markdown import Markdown

from autocoder_nano.actypes import AutoCoderArgs, SourceCodeList, SingleOutputMeta
from autocoder_nano.agent.agent_base import BaseAgent
from autocoder_nano.agent.agentic_edit_types import *
from autocoder_nano.context import get_context_manager, ConversationsPruner
from autocoder_nano.core import AutoLLM, prompt, stream_chat_with_continue
from autocoder_nano.rag.token_counter import count_tokens
from autocoder_nano.utils.formatted_log_utils import save_formatted_log
from autocoder_nano.utils.git_utils import get_uncommitted_changes
from autocoder_nano.utils.printer_utils import Printer
from autocoder_nano.agent.agentic_edit_tools import (  # Import specific resolvers
    BaseToolResolver, WebSearchToolResolver, AskFollowupQuestionToolResolver,
    AttemptCompletionToolResolver
)


printer = Printer()


REPORT_TOOL_RESOLVER_MAP: Dict[Type[BaseTool], Type[BaseToolResolver]] = {
    WebSearchTool: WebSearchToolResolver,
    AskFollowupQuestionTool: AskFollowupQuestionToolResolver,
    AttemptCompletionTool: AttemptCompletionToolResolver,  # Will stop the loop anyway
}


class AgenticReport(BaseAgent):
    def __init__(
            self, args: AutoCoderArgs, llm: AutoLLM, files: SourceCodeList, history_conversation: List[Dict[str, Any]],
            conversation_config: Optional[AgenticEditConversationConfig] = None
    ):
        super().__init__(args, llm)
        self.files = files
        self.history_conversation = history_conversation
        self.current_conversations = []
        self.shadow_manager = None
        self.file_changes: Dict[str, FileChangeEntry] = {}

        # å¯¹è¯ç®¡ç†å™¨
        self.conversation_config = conversation_config
        self.conversation_manager = get_context_manager()

        # Agentic å¯¹è¯ä¿®å‰ªå™¨
        self.agentic_pruner = ConversationsPruner(args=args, llm=self.llm)

        if self.conversation_config.action == "new":
            conversation_id = self.conversation_manager.create_conversation(
                name=self.conversation_config.query or "New Conversation",
                description=self.conversation_config.query or "New Conversation")
            self.conversation_manager.set_current_conversation(conversation_id)
        if self.conversation_config.action == "resume" and self.conversation_config.conversation_id:
            self.conversation_manager.set_current_conversation(self.conversation_config.conversation_id)

    @prompt()
    def _system_prompt_role(self):
        """
        # é¢†åŸŸç ”ç©¶å‘˜ (Strategic Research Specialist) Agent

        å›¢é˜Ÿçš„å¤šé¢†åŸŸç ”ç©¶ä¸“å®¶ã€‚ä¸ä»…ç²¾é€šæŠ€æœ¯æ¶æ„çš„æ·±åº¦è°ƒç ”ï¼Œè¿˜æ“…é•¿å¸‚åœºåˆ†æï¼Œç«äº‰å¯¹æ‰‹ç ”ç©¶ï¼Œè¡Œä¸šè¶‹åŠ¿æ´å¯Ÿå’Œäº§å“å¯è¡Œæ€§åˆ†æã€‚
        é€šè¿‡å¤šRAGçŸ¥è¯†åº“ä¸é«˜çº§è”ç½‘æœç´¢ï¼Œä¸ºæŠ€æœ¯å†³ç­–ï¼Œäº§å“è§„åˆ’å’Œå•†ä¸šæˆ˜ç•¥æä¾›åŸºäºäº‹å®ä¸æ•°æ®çš„å…¨æ–¹ä½å†³ç­–æ”¯æŒã€‚

        ## æ ¸å¿ƒèŒè´£

        - ã€æŠ€æœ¯ã€‘æ·±åº¦æŠ€æœ¯è°ƒç ”: (åŸæœ‰) å¯¹æŠ€æœ¯æ ˆã€æ¶æ„ã€å¼€æºåº“ã€ç®—æ³•ã€äº‘æœåŠ¡æˆ–å…·ä½“æŠ€æœ¯éš¾é¢˜è¿›è¡Œè°ƒç ”ã€‚
        - ã€å¸‚åœºã€‘å¸‚åœºä¸è¡Œä¸šåˆ†æ: ç ”ç©¶ç›®æ ‡å¸‚åœºçš„è§„æ¨¡ã€å¢é•¿è¶‹åŠ¿ã€ç”¨æˆ·ã€å…³é”®ç©å®¶å’Œå•†ä¸šæ¨¡å¼ã€‚
        - ã€ç«äº‰ã€‘ç«äº‰å¯¹æ‰‹åˆ†æ: æ·±åº¦ç ”ç©¶ç›´æ¥ä¸é—´æ¥ç«äº‰å¯¹æ‰‹çš„äº§å“ã€æŠ€æœ¯æ ˆã€ä¼˜åŠ£åŠ¿ã€å¸‚åœºå®šä½ã€èèµ„æƒ…å†µã€ç”¨æˆ·è¯„ä»·å’Œæœ€æ–°åŠ¨æ€ã€‚
        - ã€äº§å“ã€‘äº§å“ä¸å¯è¡Œæ€§ç ”ç©¶: åˆ†ææŸä¸ªäº§å“åˆ›æ„çš„å¯è¡Œæ€§ã€æ½œåœ¨ç”¨æˆ·ç—›ç‚¹ã€ç°æœ‰è§£å†³æ–¹æ¡ˆä»¥åŠå¸‚åœºç¼ºå£ã€‚
        - ã€ç»¼åˆã€‘ä¿¡æ¯ç»¼åˆä¸æ´å¯Ÿ: ä»æµ·é‡ä¿¡æ¯ä¸­æç‚¼å…³é”®æ´å¯Ÿï¼Œè¿æ¥æŠ€æœ¯å¯èƒ½æ€§ä¸å¸‚åœºæœºé‡ï¼Œè¯†åˆ«é£é™©ä¸æœºä¼š
        - ã€å¯ä¿¡åº¦ã€‘å¯ä¿¡åº¦è¯„ä¼°: ä¸¥æ ¼è¯„ä¼°æ‰€æœ‰ä¿¡æ¯æ¥æºçš„å¯ä¿¡åº¦ï¼Œæ— è®ºæ˜¯æŠ€æœ¯æ–‡æ¡£ã€è´¢ç»æ–°é—»ã€è¡Œä¸šæŠ¥å‘Šè¿˜æ˜¯å­¦æœ¯è®ºæ–‡ã€‚

        # å·¥ä½œæµç¨‹ä¸ç­–ç•¥

        ## 1. ç ”ç©¶ç›®æ ‡æ¾„æ¸…

        - æ¥æ”¶æ˜ç¡®çš„ç ”ç©¶ä¸»é¢˜å’Œç›®æ ‡ï¼Œä¾‹å¦‚ï¼š
            - æŠ€æœ¯ç±»é—®é¢˜
                - "ç ”ç©¶Next.js 15 vs. Remix 2.0åœ¨å¤§å‹ç”µå•†é¡¹ç›®ä¸­çš„é€‚ç”¨æ€§"
                - "ä¸ºé«˜å¹¶å‘å®æ—¶æ¶ˆæ¯æœåŠ¡åœ¨Pulsarå’ŒKafkaä¹‹é—´åšæŠ€æœ¯é€‰å‹"
                - "è§£å†³Python Pandaså¤„ç†100GBçº§CSVæ–‡ä»¶æ—¶çš„å†…å­˜æº¢å‡ºé—®é¢˜"
            - å¸‚åœº/ç«äº‰ç±»é—®é¢˜
                - "ç ”ç©¶æ™ºèƒ½æ‰‹è¡¨å¸‚åœºçš„å¥åº·ç›‘æµ‹åŠŸèƒ½è¶‹åŠ¿å’Œä¸»è¦ç«äº‰å¯¹æ‰‹"
                - "åˆ†æNotionçš„å•†ä¸šæ¨¡å¼å’Œå®ƒçš„ä¸»è¦æ›¿ä»£å“"
            - äº§å“ç±»: â€œä¸ºä¸€ä¸ªâ€˜AIå¥èº«æ•™ç»ƒâ€™çš„åˆ›ä¸šæƒ³æ³•åšåˆæ­¥çš„å¸‚åœºå’Œå¯è¡Œæ€§ç ”ç©¶â€
        - è‹¥ä»»åŠ¡æè¿°æ¨¡ç³Šï¼Œå¯é€šè¿‡ ask_followup_question å·¥å…·ï¼Œåº”ä¸»åŠ¨ä¸éœ€æ±‚å‘èµ·è€…äº¤äº’ä»¥æ˜ç¡®ç ”ç©¶èŒƒå›´ã€ä¾§é‡ç‚¹å’Œé¢„æœŸäº§å‡ºã€‚

        ## 2. ç ”ç©¶ç­–ç•¥åˆ¶å®š

        - å¤šQueryç”Ÿæˆ: é’ˆå¯¹åŒä¸€ä¸»é¢˜ï¼Œç”Ÿæˆ3-5ä¸ªä¸åŒä¾§é‡ç‚¹çš„æœç´¢æŸ¥è¯¢ï¼Œç»“åˆä¸­è‹±æ–‡å…³é”®è¯ã€‚ä¾‹å¦‚ï¼š
            - "Kafka vs Pulsar throughput benchmark 2024"
            - "Apache Pulsar ä¸­æ–‡ å®è·µ è¸©å‘"
            - "Pulsar geo-replication vs Kafka MirrorMaker"
        - é€šè¿‡ web_search å·¥å…·è¿›è¡Œè”ç½‘æ£€ç´¢
        - å¯¹ç»“æœè¿›è¡Œæ¥æºè¿‡æ»¤:
            - é«˜ä¼˜å…ˆçº§åŸŸå: github.com, stackoverflow.com, medium.com, infoq.com, reddit.com, å®˜æ–¹æ–‡æ¡£åŸŸå (*.apache.org, *.reactjs.org), æƒå¨ä¸ªäººåšå®¢ã€‚
            - ä½ä¼˜å…ˆçº§åŸŸå: å†…å®¹å†œåœºã€SEOåƒåœ¾ç«™ã€åŒ¿åwikiã€æ— æ¥æºçš„èµ„è®¯ç«™ã€‚ï¼ˆå½“å¼•ç”¨äº†ä½ä¼˜å…ˆçº§åŸŸååï¼Œåœ¨æœ€ç»ˆè¾“å‡ºç‰©ä¸­åŠ å…¥è­¦ç¤ºï¼‰
        - æ—¶é—´è¿‡æ»¤: ä¼˜å…ˆè·å–æœ€è¿‘1-2å¹´çš„ä¿¡æ¯ï¼Œç¡®ä¿æŠ€æœ¯çš„æ–°é²œåº¦ï¼Œä½†å¯¹æŸäº›åŸºç¡€æ€§ã€åŸç†æ€§çš„ç»å…¸æ–‡çŒ®å¯æ”¾å®½æ—¶é™ã€‚
        - æ ¸å¿ƒä¿¡æ¯æº
            - è¡Œä¸šæŠ¥å‘Š: Gartner, Forrester, IDC, è‰¾ç‘å’¨è¯¢ã€QuestMobileç­‰ã€‚
            - è´¢ç»ä¸å•†ä¸šæ–°é—»: Bloomberg, Reuters, 36æ°ª, è™å—…, åå°”è¡—æ—¥æŠ¥ã€‚
            - å…¬å¸ä¿¡æ¯: Crunchbase, AngelList, å¤©çœ¼æŸ¥ã€ä¼æŸ¥æŸ¥ï¼Œå…¬å¸å®˜ç½‘çš„â€œAboutâ€å’Œâ€œBlogâ€ã€‚
            - ç¤¾äº¤åª’ä½“ä¸ç¤¾åŒº: Reddit, Twitter, LinkedIn, ç‰¹å®šè¡Œä¸šçš„ä¸“ä¸šè®ºå›å’Œç¤¾ç¾¤ï¼ˆå¦‚é›ªçƒå¯¹äºæŠ•èµ„ï¼‰ï¼Œç”¨äºæ•æ‰ç”¨æˆ·çœŸå®å£°éŸ³å’Œè¶‹åŠ¿ã€‚
            - å®˜æ–¹æ•°æ®: æ”¿åºœç»Ÿè®¡ç½‘ç«™ã€è¡Œä¸šåä¼šå…¬å¼€æ•°æ®ã€‚
        - åˆ†ææ¡†æ¶
            - SWOTåˆ†æ: ç”¨äºåˆ†æç«äº‰å¯¹æ‰‹æˆ–è‡ªèº«äº§å“ï¼ˆä¼˜åŠ¿ã€åŠ£åŠ¿ã€æœºä¼šã€å¨èƒï¼‰ã€‚
            - PESTLEåˆ†æ: ç”¨äºå®è§‚ç¯å¢ƒåˆ†æï¼ˆæ”¿æ²»ã€ç»æµã€ç¤¾ä¼šã€æŠ€æœ¯ã€æ³•å¾‹ã€ç¯å¢ƒï¼‰ã€‚
            - æ³¢ç‰¹äº”åŠ›æ¨¡å‹: ç”¨äºåˆ†æè¡Œä¸šç«äº‰æ ¼å±€ã€‚

        ## 3. ä¿¡æ¯æ£€ç´¢ä¸éªŒè¯

        - ä½¿ç”¨ WebFetch/é«˜çº§æœç´¢ åŠŸèƒ½è·å–é“¾æ¥çš„å®Œæ•´å†…å®¹ï¼Œé¿å…ä»…ä¾èµ–æ‘˜è¦ã€‚
        - äº¤å‰éªŒè¯ (Cross-Reference): å¯¹ä»»ä½•å…³é”®æ€§ç»“è®ºï¼ˆå¦‚æ€§èƒ½æ•°æ®ã€ä¼˜ç¼ºç‚¹ï¼‰å¿…é¡»åœ¨è‡³å°‘ä¸¤ä¸ªä»¥ä¸Šå¯ä¿¡æ¥æºä¸­æ‰¾åˆ°ä½è¯ã€‚
        - è¿½æº¯æºå¤´: æŸ¥çœ‹åšæ–‡å¼•ç”¨çš„åŸºå‡†æµ‹è¯•æŠ¥å‘Šã€GitHub Issueçš„åŸå§‹è®¨è®ºã€å®˜æ–¹å‘å¸ƒè¯´æ˜çš„åŸæ–‡ã€‚
        - å¯¹å¸‚åœºæ•°æ®å’Œé¢„æµ‹æ€§ç»“è®ºä¿æŒé«˜åº¦è­¦æƒ•ï¼Œå¿…é¡»è¿½æº¯æ•°æ®æºå¤´ï¼ˆæ˜¯æ¥è‡ªçŸ¥åæœºæ„çš„æŠ½æ ·è°ƒæŸ¥è¿˜æ˜¯å…¬å¸è‡ªå·±çš„æ–°é—»ç¨¿ï¼Ÿï¼‰ã€‚
        - å¯¹æ¯”å¤šä¸ªæ¥æºçš„å¸‚åœºæ•°æ®ï¼Œå–å…±è¯†æˆ–ç†è§£å…¶ç»Ÿè®¡å£å¾„çš„å·®å¼‚ã€‚
        - åŒºåˆ†äº‹å®ï¼ˆå…¬å¸Aå‘å¸ƒäº†äº§å“Bï¼‰å’Œè§‚ç‚¹ï¼ˆâ€œåˆ†æå¸ˆè®¤ä¸ºå…¬å¸Aå°†ç»Ÿæ²»å¸‚åœºâ€ï¼‰ï¼Œå¹¶æ˜ç¡®æ ‡æ³¨ã€‚

        ## 4. ä¿¡æ¯åˆ†æä¸ç»¼åˆ

        - æå–ä¸åŒæ–¹æ¡ˆçš„å¯¹æ¯”ç»´åº¦ï¼Œä¾‹å¦‚ï¼š
            - æ€§èƒ½: ååé‡ã€å»¶è¿Ÿã€èµ„æºå ç”¨
            - åŠŸèƒ½: æ ¸å¿ƒç‰¹æ€§ã€ç”Ÿæ€ç³»ç»Ÿã€å·¥å…·é“¾æˆç†Ÿåº¦
            - æˆæœ¬: å¼€æºåè®®ã€æ‰˜ç®¡æœåŠ¡ä»·æ ¼ã€å¼€å‘è¿ç»´äººåŠ›æˆæœ¬
            - ç¤¾åŒº: æ´»è·ƒåº¦ã€å­¦ä¹ èµ„æ–™ä¸°å¯Œåº¦ã€æ‹›è˜å¸‚åœºçƒ­åº¦
            - é€‚ç”¨åœºæ™¯: æœ€é€‚åˆçš„åº”ç”¨åœºæ™¯å’Œæœ€ä¸æ“…é•¿çš„åœºæ™¯
        - æŠ€æœ¯ç ”ç©¶ä¸å¸‚åœºç ”ç©¶ç›¸ç»“åˆã€‚ä¾‹å¦‚ï¼š
            - â€œç«äº‰å¯¹æ‰‹Cä½¿ç”¨äº†æŠ€æœ¯Xï¼Œè¿™å¯èƒ½æ˜¯å…¶å®ç°åŠŸèƒ½Yï¼ˆå¸‚åœºä¼˜åŠ¿ï¼‰çš„å…³é”®ã€‚â€
            - â€œå¸‚åœºè¶‹åŠ¿Zæ­£åœ¨å…´èµ·ï¼Œè¿™æ„å‘³ç€æˆ‘ä»¬å¯¹æŠ€æœ¯Wçš„æŠ•å…¥ç¬¦åˆæœªæ¥æ–¹å‘ã€‚â€
        - ä¸ä»…å›ç­”â€œæ˜¯ä»€ä¹ˆâ€ï¼Œæ›´è¦å°è¯•å›ç­”â€œæ‰€ä»¥å‘¢ï¼Ÿâ€ï¼ˆSo What?ï¼‰ï¼Œä¸ºå›¢é˜Ÿæ­ç¤ºèƒŒåçš„å«ä¹‰å’Œè¡ŒåŠ¨å»ºè®®ã€‚

        # è¾“å‡ºè§„èŒƒ (äº¤ä»˜ç‰©)

        ## ç»¼åˆæ€§ç ”ç©¶æŠ¥å‘Šï¼ˆæ¨èç»“æ„ï¼‰ï¼š

        1. æ‘˜è¦ä¸æ ¸å¿ƒç»“è®º: ä¸€é¡µçº¸è¯´æ¸…æ‰€æœ‰å…³é”®å‘ç°å’Œå»ºè®®ã€‚
        2. ç ”ç©¶èƒŒæ™¯ä¸æ–¹æ³•: é˜æ˜ç ”ç©¶ç›®æ ‡å’Œä½¿ç”¨çš„æ–¹æ³•è®ºã€‚
        3. å¸‚åœºæ ¼å±€åˆ†æ: å¸‚åœºè§„æ¨¡ã€å¢é•¿ã€å…³é”®ç©å®¶ã€è¶‹åŠ¿ã€‚
        4. ç«äº‰å¯¹æ‰‹æ·±åº¦å‰–æ: å¯é€‰2-3ä¸ªä¸»è¦ç«äº‰å¯¹æ‰‹ï¼Œä»äº§å“ã€æŠ€æœ¯ã€è¥é”€ã€ç”¨æˆ·ç­‰å¤šç»´åº¦å¯¹æ¯”ã€‚
        5. æŠ€æœ¯æ–¹æ¡ˆè°ƒç ”: åŸæœ‰çš„æŠ€æœ¯å¯¹æ¯”åˆ†æï¼Œå¹¶è¯´æ˜å…¶ä¸å¸‚åœºéœ€æ±‚çš„å…³è”ã€‚
        6. æœºä¼šã€é£é™©ä¸å»ºè®® (Opportunities, Risks & Recommendations): ç»¼åˆæ‰€æœ‰å‘ç°ï¼Œæå‡ºæˆ˜ç•¥æ€§çš„å»ºè®®ã€‚
        7. é™„å½•ä¸æ•°æ®æ¥æº: æ‰€æœ‰å¼•ç”¨çš„æ•°æ®ã€å›¾è¡¨å’Œæ¥æºé“¾æ¥ã€‚

        ## å¯¹äºå¿«é€Ÿä»»åŠ¡ï¼Œå¯ä½¿ç”¨ç²¾ç®€æ¡†æ¶ï¼š

        1.ã€å¸‚åœºã€‘: è¶‹åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿè§„æ¨¡å¤šå¤§ï¼Ÿ
        2.ã€ç«äº‰ã€‘: è°åœ¨åšï¼Ÿåšå¾—æ€ä¹ˆæ ·ï¼Ÿ
        3.ã€æŠ€æœ¯ã€‘: ç”¨ä»€ä¹ˆåšï¼Ÿæœ‰ä»€ä¹ˆé€‰æ‹©ï¼Ÿ
        4.ã€ç»“è®ºã€‘: æˆ‘ä»¬çš„æœºä¼šåœ¨å“ªï¼Ÿé£é™©æ˜¯ä»€ä¹ˆï¼Ÿä¸‹ä¸€æ­¥å»ºè®®ï¼Ÿ

        # çº¦æŸä¸æ ¸å¿ƒè§„åˆ™

        - ä¸»é¢˜åŠç›®æ ‡è¦æ˜ç¡®ï¼Œå¿…è¦æ—¶å¯ä¸ç”¨æˆ·æ²Ÿé€šç¡®è®¤
        - ä¸€æ¬¡ web_search å·¥å…·è°ƒç”¨çš„ç»“æœä¸è¶³ä»¥æ”¯æ’‘ç»“è®ºæ—¶ï¼Œå¯ä»¥é€šè¿‡å˜æ¢ Query å†æ¬¡æ£€ç´¢ï¼Œä½†æ˜¯æ€»æ£€ç´¢æ¬¡æ•°ä¸èƒ½è¶…è¿‡2æ¬¡
        - ç”¨æˆ·æ²¡æœ‰æ˜ç¡®è¯´æ˜çš„æƒ…å†µä¸‹ï¼Œä½¿ç”¨ç»¼åˆæ€§ç ”ç©¶æŠ¥å‘Šç»“æ„
        - æœ€åä½¿ç”¨ attempt_completion å·¥å…·è¾“å‡ºæŠ¥å‘Š
        """

    @prompt()
    def _system_prompt_tools(self):
        """
        # å·¥å…·ä½¿ç”¨è¯´æ˜

        1. ä½ å¯ä½¿ç”¨ä¸€ç³»åˆ—å·¥å…·ï¼Œéƒ¨åˆ†å·¥å…·éœ€ç»ç”¨æˆ·æ‰¹å‡†æ‰èƒ½æ‰§è¡Œã€‚
        2. æ¯æ¡æ¶ˆæ¯ä¸­ä»…èƒ½ä½¿ç”¨ä¸€ä¸ªå·¥å…·ï¼Œç”¨æˆ·å›å¤ä¸­ä¼šåŒ…å«è¯¥å·¥å…·çš„æ‰§è¡Œç»“æœã€‚
        3. ä½ è¦å€ŸåŠ©å·¥å…·é€æ­¥å®Œæˆç»™å®šä»»åŠ¡ï¼Œæ¯ä¸ªå·¥å…·çš„ä½¿ç”¨éƒ½éœ€ä¾æ®å‰ä¸€ä¸ªå·¥å…·çš„ä½¿ç”¨ç»“æœã€‚

        # å·¥å…·ä½¿ç”¨æ ¼å¼

        å·¥å…·ä½¿ç”¨é‡‡ç”¨ XML é£æ ¼æ ‡ç­¾è¿›è¡Œæ ¼å¼åŒ–ã€‚å·¥å…·åç§°åŒ…å«åœ¨å¼€å§‹å’Œç»“æŸæ ‡ç­¾å†…ï¼Œæ¯ä¸ªå‚æ•°åŒæ ·åŒ…å«åœ¨å„è‡ªçš„æ ‡ç­¾ä¸­ã€‚å…¶ç»“æ„å¦‚ä¸‹ï¼š
        <tool_name>
        <parameter1_name>value1</parameter1_name>
        <parameter2_name>value2</parameter2_name>
        ...
        </tool_name>
        ä¾‹å¦‚ï¼š
        <read_file>
        <path>src/main.js</path>
        </read_file>

        ä¸€å®šè¦ä¸¥æ ¼éµå¾ªæ­¤å·¥å…·ä½¿ç”¨æ ¼å¼ï¼Œä»¥ç¡®ä¿æ­£ç¡®è§£æå’Œæ‰§è¡Œã€‚

        # å·¥å…·åˆ—è¡¨

        ## web_searchï¼ˆè”ç½‘æ£€ç´¢ï¼‰
        æè¿°ï¼š
        - é€šè¿‡æœç´¢å¼•æ“åœ¨äº’è”ç½‘ä¸Šæ£€ç´¢ç›¸å…³ä¿¡æ¯ï¼Œæ”¯æŒå…³é”®è¯æœç´¢ã€‚
        å‚æ•°ï¼š
        - queryï¼ˆå¿…å¡«ï¼‰ï¼šè¦æœç´¢çš„å…³é”®è¯æˆ–çŸ­è¯­
        ç”¨æ³•è¯´æ˜ï¼š
        <web_search>
        <query>Search keywords here</query>
        </web_search>
        ç”¨æ³•ç¤ºä¾‹ï¼š
        åœºæ™¯ä¸€ï¼šåŸºç¡€å…³é”®è¯æœç´¢
        ç›®æ ‡ï¼šæŸ¥æ‰¾å…³äºç¥ç»ç½‘ç»œçš„ç ”ç©¶è¿›å±•ã€‚
        æ€ç»´è¿‡ç¨‹ï¼šé€šè¿‡ä¸€äº›å…³é”®è¯ï¼Œæ¥è·å–æœ‰å…³äºç¥ç»ç½‘ç»œå­¦æœ¯ä¿¡æ¯
        <web_search>
        <query>neural network research advances</query>
        </web_search>
        åœºæ™¯äºŒï¼šç®€å•çŸ­è¯­æœç´¢
        ç›®æ ‡ï¼šæŸ¥æ‰¾å…³äºé‡å­è®¡ç®—çš„è¯¦ç»†ä»‹ç»ã€‚
        æ€ç»´è¿‡ç¨‹ï¼šé€šè¿‡ä¸€ä¸ªçŸ­è¯­ï¼Œæ¥è·å–æœ‰å…³äºé‡å­è®¡ç®—çš„ä¿¡æ¯
        <web_search>
        <query>é‡å­è®¡ç®—çš„è¯¦ç»†ä»‹ç»</query>
        </web_search>

        ## ask_followup_questionï¼ˆæå‡ºåç»­é—®é¢˜ï¼‰
        æè¿°ï¼š
        - å‘ç”¨æˆ·æé—®è·å–ä»»åŠ¡æ‰€éœ€ä¿¡æ¯ã€‚
        - å½“é‡åˆ°æ­§ä¹‰ï¼Œéœ€è¦æ¾„æ¸…æˆ–éœ€è¦æ›´å¤šç»†èŠ‚ä»¥æœ‰æ•ˆæ¨è¿›æ—¶ä½¿ç”¨æ­¤å·¥å…·ã€‚
        - å®ƒé€šè¿‡ä¸ç”¨æˆ·ç›´æ¥æ²Ÿé€šå®ç°äº¤äº’å¼é—®é¢˜è§£å†³ï¼Œåº”æ˜æ™ºä½¿ç”¨ï¼Œä»¥åœ¨æ”¶é›†å¿…è¦ä¿¡æ¯å’Œé¿å…è¿‡å¤šæ¥å›æ²Ÿé€šä¹‹é—´å–å¾—å¹³è¡¡ã€‚
        å‚æ•°ï¼š
        - questionï¼ˆå¿…å¡«ï¼‰ï¼šæ¸…æ™°å…·ä½“çš„é—®é¢˜ã€‚
        - optionsï¼ˆå¯é€‰ï¼‰ï¼š2-5ä¸ªé€‰é¡¹çš„æ•°ç»„ï¼Œæ¯ä¸ªé€‰é¡¹åº”ä¸ºæè¿°å¯èƒ½ç­”æ¡ˆçš„å­—ç¬¦ä¸²ï¼Œå¹¶éæ€»æ˜¯éœ€è¦æä¾›é€‰é¡¹ï¼Œå°‘æ•°æƒ…å†µä¸‹æœ‰åŠ©äºé¿å…ç”¨æˆ·æ‰‹åŠ¨è¾“å…¥ã€‚
        ç”¨æ³•è¯´æ˜ï¼š
        <ask_followup_question>
        <question>Your question here</question>
        <options>
        Array of options here (optional), e.g. ["Option 1", "Option 2", "Option 3"]
        </options>
        </ask_followup_question>
        ç”¨æ³•ç¤ºä¾‹ï¼š
        åœºæ™¯ä¸€ï¼šæ¾„æ¸…éœ€æ±‚
        ç›®æ ‡ï¼šç”¨æˆ·åªè¯´è¦ä¿®æ”¹æ–‡ä»¶ï¼Œä½†æ²¡æœ‰æä¾›æ–‡ä»¶åã€‚
        æ€ç»´è¿‡ç¨‹ï¼šéœ€è¦å‘ç”¨æˆ·è¯¢é—®å…·ä½“è¦ä¿®æ”¹å“ªä¸ªæ–‡ä»¶ï¼Œæä¾›é€‰é¡¹å¯ä»¥æé«˜æ•ˆç‡ã€‚
        <ask_followup_question>
        <question>è¯·é—®æ‚¨è¦ä¿®æ”¹å“ªä¸ªæ–‡ä»¶ï¼Ÿ</question>
        <options>
        ["src/app.js", "src/index.js", "package.json"]
        </options>
        </ask_followup_question>
        åœºæ™¯äºŒï¼šè¯¢é—®ç”¨æˆ·åå¥½
        ç›®æ ‡ï¼šåœ¨å®ç°æ–°åŠŸèƒ½æ—¶ï¼Œæœ‰å¤šç§æŠ€æœ¯æ–¹æ¡ˆå¯ä¾›é€‰æ‹©ã€‚
        æ€ç»´è¿‡ç¨‹ï¼šä¸ºäº†ç¡®ä¿æœ€ç»ˆå®ç°ç¬¦åˆç”¨æˆ·é¢„æœŸï¼Œéœ€è¦è¯¢é—®ç”¨æˆ·æ›´å€¾å‘äºå“ªç§æ–¹æ¡ˆã€‚
        <ask_followup_question>
        <question>æ‚¨å¸Œæœ›ä½¿ç”¨å“ªä¸ªæ¡†æ¶æ¥å®ç°å‰ç«¯ç•Œé¢ï¼Ÿ</question>
        <options>
        ["React", "Vue", "Angular"]
        </options>
        </ask_followup_question>

        ## attempt_completionï¼ˆå°è¯•å®Œæˆä»»åŠ¡ï¼‰
        æè¿°ï¼š
        - æ¯æ¬¡å·¥å…·ä½¿ç”¨åï¼Œç”¨æˆ·ä¼šå›å¤è¯¥å·¥å…·ä½¿ç”¨çš„ç»“æœï¼Œå³æ˜¯å¦æˆåŠŸä»¥åŠå¤±è´¥åŸå› ï¼ˆå¦‚æœ‰ï¼‰ã€‚
        - ä¸€æ—¦æ”¶åˆ°å·¥å…·ä½¿ç”¨ç»“æœå¹¶ç¡®è®¤ä»»åŠ¡å®Œæˆï¼Œä½¿ç”¨æ­¤å·¥å…·å‘ç”¨æˆ·å±•ç¤ºå·¥ä½œæˆæœã€‚
        - å¯é€‰åœ°ï¼Œä½ å¯ä»¥æä¾›ä¸€ä¸ª CLI å‘½ä»¤æ¥å±•ç¤ºå·¥ä½œæˆæœã€‚ç”¨æˆ·å¯èƒ½ä¼šæä¾›åé¦ˆï¼Œä½ å¯æ®æ­¤è¿›è¡Œæ”¹è¿›å¹¶å†æ¬¡å°è¯•ã€‚
        é‡è¦æç¤ºï¼š
        - åœ¨ç¡®è®¤ç”¨æˆ·å·²ç¡®è®¤ä¹‹å‰çš„å·¥å…·ä½¿ç”¨æˆåŠŸä¹‹å‰ï¼Œä¸å¾—ä½¿ç”¨æ­¤å·¥å…·ã€‚å¦åˆ™å°†å¯¼è‡´ä»£ç æŸåå’Œç³»ç»Ÿæ•…éšœã€‚
        - åœ¨ä½¿ç”¨æ­¤å·¥å…·ä¹‹å‰ï¼Œå¿…é¡»åœ¨<thinking></thinking>æ ‡ç­¾ä¸­è‡ªé—®æ˜¯å¦å·²ä»ç”¨æˆ·å¤„ç¡®è®¤ä¹‹å‰çš„å·¥å…·ä½¿ç”¨æˆåŠŸã€‚å¦‚æœæ²¡æœ‰ï¼Œåˆ™ä¸è¦ä½¿ç”¨æ­¤å·¥å…·ã€‚
        å‚æ•°ï¼š
        - resultï¼ˆå¿…å¡«ï¼‰ï¼šä»»åŠ¡çš„ç»“æœï¼Œåº”ä»¥æœ€ç»ˆå½¢å¼è¡¨è¿°ï¼Œæ— éœ€ç”¨æˆ·è¿›ä¸€æ­¥è¾“å…¥ï¼Œä¸å¾—åœ¨ç»“æœç»“å°¾æå‡ºé—®é¢˜æˆ–æä¾›è¿›ä¸€æ­¥å¸®åŠ©ã€‚
        - commandï¼ˆå¯é€‰ï¼‰ï¼šç”¨äºå‘ç”¨æˆ·æ¼”ç¤ºç»“æœçš„ CLI å‘½ä»¤ã€‚
        ç”¨æ³•è¯´æ˜ï¼š
        <attempt_completion>
        <result>
        Your final result description here
        </result>
        <command>Command to demonstrate result (optional)</command>
        </attempt_completion>
        ç”¨æ³•ç¤ºä¾‹ï¼š
        åœºæ™¯ä¸€ï¼šè¾“å‡ºç»¼åˆæ€§ç ”ç©¶æŠ¥å‘Šå†…å®¹
        ç›®æ ‡ï¼šå‘ç”¨æˆ·å±•ç¤ºç»¼åˆæ€§ç ”ç©¶æŠ¥å‘Šå†…å®¹ã€‚
        æ€ç»´è¿‡ç¨‹ï¼šæ‰€æœ‰æŸ¥è¯¢æ£€ç´¢å·¥ä½œéƒ½å·²å®Œæˆï¼Œé€šè¿‡éªŒè¯ï¼Œåˆ†æï¼Œç°åœ¨å‘ç”¨æˆ·å±•ç¤ºç»¼åˆæ€§ç ”ç©¶æŠ¥å‘Šå†…å®¹ã€‚
        <attempt_completion>
        <result>
        ç»¼åˆæ€§ç ”ç©¶æŠ¥å‘Šå…·ä½“å†…å®¹
        </result>
        </attempt_completion>

        # é”™è¯¯å¤„ç†
        - å¦‚æœå·¥å…·è°ƒç”¨å¤±è´¥ï¼Œä½ éœ€è¦åˆ†æé”™è¯¯ä¿¡æ¯ï¼Œå¹¶é‡æ–°å°è¯•ï¼Œæˆ–è€…å‘ç”¨æˆ·æŠ¥å‘Šé”™è¯¯å¹¶è¯·æ±‚å¸®åŠ©ï¼ˆä½¿ç”¨ ask_followup_question å·¥å…·ï¼‰

        ## å·¥å…·ç†”æ–­æœºåˆ¶
        - å·¥å…·è¿ç»­å¤±è´¥2æ¬¡æ—¶å¯åŠ¨å¤‡é€‰æ–¹æ¡ˆ
        - è‡ªåŠ¨æ ‡æ³¨è¡Œä¸šæƒ¯ä¾‹æ–¹æ¡ˆä¾›ç”¨æˆ·ç¡®è®¤
        """

    def analyze(self, request: AgenticEditRequest) -> (
            Generator)[Union[LLMOutputEvent, LLMThinkingEvent, ToolCallEvent, ToolResultEvent, CompletionEvent,
                             ErrorEvent, WindowLengthChangeEvent, TokenUsageEvent,
                             PlanModeRespondEvent] | None, None, None]:
        conversations = [
            {"role": "system", "content": self._system_prompt_role.prompt()},
            {"role": "system", "content": self._system_prompt_tools.prompt()}
        ]

        printer.print_key_value(
            {"é•¿åº¦(tokens)": f"{count_tokens(json.dumps(conversations, ensure_ascii=False))}"}, title="ç³»ç»Ÿæç¤ºè¯"
        )

        if self.conversation_config.action == "resume":
            current_conversation = self.conversation_manager.get_current_conversation()
            # å¦‚æœç»§ç»­çš„æ˜¯å½“å‰çš„å¯¹è¯ï¼Œå°†å…¶æ¶ˆæ¯åŠ å…¥åˆ° conversations ä¸­
            if current_conversation and current_conversation.get('messages'):
                for message in current_conversation['messages']:
                    # ç¡®ä¿æ¶ˆæ¯æ ¼å¼æ­£ç¡®ï¼ˆåŒ…å« role å’Œ content å­—æ®µï¼‰
                    if isinstance(message, dict) and 'role' in message and 'content' in message:
                        conversations.append({
                            "role": message['role'],
                            "content": message['content']
                        })
                printer.print_text(f"æ¢å¤å¯¹è¯ï¼Œå·²æœ‰ {len(current_conversation['messages'])} æ¡ç°æœ‰æ¶ˆæ¯", style="green")
        if self.conversation_manager.get_current_conversation_id() is None:
            conv_id = self.conversation_manager.create_conversation(name=self.conversation_config.query,
                                                                    description=self.conversation_config.query)
            self.conversation_manager.set_current_conversation(conv_id)

        self.conversation_manager.set_current_conversation(self.conversation_manager.get_current_conversation_id())

        conversations.append({
            "role": "user", "content": request.user_input
        })

        self.conversation_manager.append_message_to_current(
            role="user",
            content=request.user_input,
            metadata={})

        self.current_conversations = conversations

        # è®¡ç®—åˆå§‹å¯¹è¯çª—å£é•¿åº¦å¹¶è§¦å‘äº‹ä»¶
        conversation_str = json.dumps(conversations, ensure_ascii=False)
        current_tokens = count_tokens(conversation_str)
        yield WindowLengthChangeEvent(tokens_used=current_tokens)

        iteration_count = 0
        tool_executed = False
        should_yield_completion_event = False
        completion_event = None

        while True:
            iteration_count += 1
            tool_executed = False
            last_message = conversations[-1]
            printer.print_key_value(
                {"å½“å‰": f"ç¬¬ {iteration_count} è½®", "å†å²ä¼šè¯é•¿åº¦": f"{len(conversations)}"}, title="LLM äº¤äº’å¾ªç¯"
            )

            if last_message["role"] == "assistant":
                if should_yield_completion_event:
                    if completion_event is None:
                        yield CompletionEvent(completion=AttemptCompletionTool(
                            result=last_message["content"],
                            command=""
                        ), completion_xml="")
                    else:
                        yield completion_event
                break

            assistant_buffer = ""

            # å®é™…è¯·æ±‚å¤§æ¨¡å‹
            llm_response_gen = stream_chat_with_continue(
                llm=self.llm,
                conversations=self.agentic_pruner.prune_conversations(deepcopy(conversations)),
                llm_config={},  # Placeholder for future LLM configs
                args=self.args
            )

            parsed_events = self.stream_and_parse_llm_response(llm_response_gen)

            event_count = 0
            mark_event_should_finish = False
            for event in parsed_events:
                event_count += 1

                if mark_event_should_finish:
                    if isinstance(event, TokenUsageEvent):
                        yield event
                    continue

                if isinstance(event, (LLMOutputEvent, LLMThinkingEvent)):
                    assistant_buffer += event.text
                    yield event  # Yield text/thinking immediately for display

                elif isinstance(event, ToolCallEvent):
                    tool_executed = True
                    tool_obj = event.tool
                    tool_name = type(tool_obj).__name__
                    tool_xml = event.tool_xml  # Already reconstructed by parser

                    # Append assistant's thoughts and the tool call to history
                    printer.print_panel(content=f"tool_xml \n{tool_xml}", title=f"ğŸ› ï¸ å·¥å…·è§¦å‘: {tool_name}",
                                        center=True)

                    # è®°å½•å½“å‰å¯¹è¯çš„tokenæ•°é‡
                    conversations.append({
                        "role": "assistant",
                        "content": assistant_buffer + tool_xml
                    })
                    self.conversation_manager.append_message_to_current(
                        role="assistant",
                        content=assistant_buffer + tool_xml,
                        metadata={})
                    assistant_buffer = ""  # Reset buffer after tool call

                    # è®¡ç®—å½“å‰å¯¹è¯çš„æ€» token æ•°é‡å¹¶è§¦å‘äº‹ä»¶
                    current_conversation_str = json.dumps(conversations, ensure_ascii=False)
                    total_tokens = count_tokens(current_conversation_str)
                    yield WindowLengthChangeEvent(tokens_used=total_tokens)

                    yield event  # Yield the ToolCallEvent for display

                    # Handle AttemptCompletion separately as it ends the loop
                    if isinstance(tool_obj, AttemptCompletionTool):
                        printer.print_panel(content=f"å®Œæˆç»“æœ: {tool_obj.result[:50]}...",
                                            title="AttemptCompletionToolï¼Œæ­£åœ¨ç»“æŸä¼šè¯", center=True)
                        completion_event = CompletionEvent(completion=tool_obj, completion_xml=tool_xml)
                        # save_formatted_log(self.args.source_dir, json.dumps(conversations, ensure_ascii=False),
                        #                    "agentic_conversation")
                        mark_event_should_finish = True
                        should_yield_completion_event = True
                        continue

                    if isinstance(tool_obj, PlanModeRespondTool):
                        printer.print_panel(content=f"Plan æ¨¡å¼å“åº”å†…å®¹: {tool_obj.response[:50]}...",
                                            title="PlanModeRespondToolï¼Œæ­£åœ¨ç»“æŸä¼šè¯", center=True)
                        yield PlanModeRespondEvent(completion=tool_obj, completion_xml=tool_xml)
                        # save_formatted_log(self.args.source_dir, json.dumps(conversations, ensure_ascii=False),
                        #                    "agentic_conversation")
                        mark_event_should_finish = True
                        continue

                    # Resolve the tool
                    resolver_cls = REPORT_TOOL_RESOLVER_MAP.get(type(tool_obj))
                    if not resolver_cls:
                        tool_result = ToolResult(
                            success=False, message="é”™è¯¯ï¼šå·¥å…·è§£æå™¨æœªå®ç°.", content=None)
                        result_event = ToolResultEvent(tool_name=type(tool_obj).__name__, result=tool_result)
                        error_xml = (f"<tool_result tool_name='{type(tool_obj).__name__}' success='false'>"
                                     f"<message>Error: Tool resolver not implemented.</message>"
                                     f"<content></content></tool_result>")
                    else:
                        try:
                            resolver = resolver_cls(agent=self, tool=tool_obj, args=self.args)
                            tool_result: ToolResult = resolver.resolve()
                            result_event = ToolResultEvent(tool_name=type(tool_obj).__name__, result=tool_result)

                            # Prepare XML for conversation history
                            escaped_message = xml.sax.saxutils.escape(tool_result.message)
                            content_str = str(
                                tool_result.content) if tool_result.content is not None else ""
                            escaped_content = xml.sax.saxutils.escape(
                                content_str)
                            error_xml = (
                                f"<tool_result tool_name='{type(tool_obj).__name__}' success='{str(tool_result.success).lower()}'>"
                                f"<message>{escaped_message}</message>"
                                f"<content>{escaped_content}</content>"
                                f"</tool_result>"
                            )
                        except Exception as e:
                            error_message = f"Critical Error during tool execution: {e}"
                            tool_result = ToolResult(success=False, message=error_message, content=None)
                            result_event = ToolResultEvent(tool_name=type(tool_obj).__name__, result=tool_result)
                            escaped_error = xml.sax.saxutils.escape(error_message)
                            error_xml = (f"<tool_result tool_name='{type(tool_obj).__name__}' success='false'>"
                                         f"<message>{escaped_error}</message>"
                                         f"<content></content></tool_result>")

                    yield result_event  # Yield the ToolResultEvent for display

                    # æ·»åŠ å·¥å…·ç»“æœåˆ°å¯¹è¯å†å²
                    conversations.append({
                        "role": "user",  # Simulating the user providing the tool result
                        "content": error_xml
                    })
                    self.conversation_manager.append_message_to_current(
                        role="user",
                        content=error_xml,
                        metadata={})

                    # è®¡ç®—å½“å‰å¯¹è¯çš„æ€» token æ•°é‡å¹¶è§¦å‘äº‹ä»¶
                    current_conversation_str = json.dumps(conversations, ensure_ascii=False)
                    total_tokens = count_tokens(current_conversation_str)
                    yield WindowLengthChangeEvent(tokens_used=total_tokens)

                    # ä¸€æ¬¡äº¤äº’åªèƒ½æœ‰ä¸€æ¬¡å·¥å…·ï¼Œå‰©ä¸‹çš„å…¶å®å°±æ²¡æœ‰ç”¨äº†ï¼Œä½†æ˜¯å¦‚æœä¸è®©æµå¼å¤„ç†å®Œï¼Œæˆ‘ä»¬å°±æ— æ³•è·å–æœåŠ¡ç«¯
                    # è¿”å›çš„tokenæ¶ˆè€—å’Œè®¡è´¹ï¼Œæ‰€ä»¥é€šè¿‡æ­¤æ ‡è®°æ¥å®Œæˆè¿›å…¥ç©ºè½¬ï¼Œç›´åˆ°æµå¼èµ°å®Œï¼Œè·å–åˆ°æœ€åçš„tokenæ¶ˆè€—å’Œè®¡è´¹
                    mark_event_should_finish = True

                elif isinstance(event, ErrorEvent):
                    yield event
                elif isinstance(event, TokenUsageEvent):
                    yield event

            if not tool_executed:
                # No tool executed in this LLM response cycle
                printer.print_text("LLMå“åº”å®Œæˆ, æœªæ‰§è¡Œä»»ä½•å·¥å…·", style="yellow")
                if assistant_buffer:
                    printer.print_text(f"å°† Assistant Buffer å†…å®¹å†™å…¥ä¼šè¯å†å²ï¼ˆå­—ç¬¦æ•°ï¼š{len(assistant_buffer)}ï¼‰")

                    last_message = conversations[-1]
                    if last_message["role"] != "assistant":
                        printer.print_text("æ·»åŠ æ–°çš„ Assistant æ¶ˆæ¯", style="green")
                        conversations.append({"role": "assistant", "content": assistant_buffer})
                        self.conversation_manager.append_message_to_current(
                            role="assistant", content=assistant_buffer, metadata={})
                    elif last_message["role"] == "assistant":
                        printer.print_text("è¿½åŠ å·²å­˜åœ¨çš„ Assistant æ¶ˆæ¯")
                        last_message["content"] += assistant_buffer

                    # è®¡ç®—å½“å‰å¯¹è¯çš„æ€» token æ•°é‡å¹¶è§¦å‘äº‹ä»¶
                    current_conversation_str = json.dumps(conversations, ensure_ascii=False)
                    total_tokens = count_tokens(current_conversation_str)
                    yield WindowLengthChangeEvent(tokens_used=total_tokens)

                # æ·»åŠ ç³»ç»Ÿæç¤ºï¼Œè¦æ±‚LLMå¿…é¡»ä½¿ç”¨å·¥å…·æˆ–æ˜ç¡®ç»“æŸï¼Œè€Œä¸æ˜¯ç›´æ¥é€€å‡º
                printer.print_text("æ­£åœ¨æ·»åŠ ç³»ç»Ÿæç¤º: è¯·ä½¿ç”¨å·¥å…·æˆ–å°è¯•ç›´æ¥ç”Ÿæˆç»“æœ", style="green")

                conversations.append({
                    "role": "user",
                    "content": "NOTE: You must use an appropriate tool (such as read_file, write_to_file, "
                               "execute_command, etc.) or explicitly complete the task (using attempt_completion). Do "
                               "not provide text responses without taking concrete actions. Please select a suitable "
                               "tool to continue based on the user's task."
                })
                self.conversation_manager.append_message_to_current(
                    role="user",
                    content="NOTE: You must use an appropriate tool (such as read_file, write_to_file, "
                            "execute_command, etc.) or explicitly complete the task (using attempt_completion). Do "
                            "not provide text responses without taking concrete actions. Please select a suitable "
                            "tool to continue based on the user's task.",
                    metadata={})

                # è®¡ç®—å½“å‰å¯¹è¯çš„æ€» token æ•°é‡å¹¶è§¦å‘äº‹ä»¶
                current_conversation_str = json.dumps(conversations, ensure_ascii=False)
                total_tokens = count_tokens(current_conversation_str)
                yield WindowLengthChangeEvent(tokens_used=total_tokens)
                # ç»§ç»­å¾ªç¯ï¼Œè®© LLM å†æ€è€ƒï¼Œè€Œä¸æ˜¯ break
                printer.print_text("æŒç»­è¿è¡Œ LLM äº¤äº’å¾ªç¯ï¼ˆä¿æŒä¸ä¸­æ–­ï¼‰", style="green")
                continue

        printer.print_text(f"Agentic Report åˆ†æå¾ªç¯å·²å®Œæˆï¼Œå…±æ‰§è¡Œ {iteration_count} æ¬¡è¿­ä»£.")
        save_formatted_log(self.args.source_dir, json.dumps(conversations, ensure_ascii=False),
                           "agentic_report_conversation")

    def apply_pre_changes(self):
        uncommitted_changes = get_uncommitted_changes(self.args.source_dir)
        if uncommitted_changes != "No uncommitted changes found.":
            raise Exception("ä»£ç ä¸­åŒ…å«æœªæäº¤çš„æ›´æ–°,è¯·æ‰§è¡Œ/commit")

    def run_in_terminal(self, request: AgenticEditRequest):
        project_name = os.path.basename(os.path.abspath(self.args.source_dir))

        printer.print_key_value(
            items={"é¡¹ç›®å": f"{project_name}", "ç”¨æˆ·ç›®æ ‡": f"{request.user_input}"}, title="Agentic Report å¼€å§‹è¿è¡Œ"
        )

        # ç”¨äºç´¯è®¡TokenUsageEventæ•°æ®
        accumulated_token_usage = {
            "model_name": "",
            "input_tokens": 0,
            "output_tokens": 0,
        }

        try:
            self.apply_pre_changes()  # åœ¨å¼€å§‹ Agentic Ask ä¹‹å‰å…ˆåˆ¤æ–­æ˜¯å¦æœ‰æœªæäº¤å˜æ›´,æœ‰å˜æ›´åˆ™ç›´æ¥é€€å‡º
            event_stream = self.analyze(request)
            for event in event_stream:
                if isinstance(event, TokenUsageEvent):
                    last_meta: SingleOutputMeta = event.usage

                    # ç´¯è®¡tokenä½¿ç”¨æƒ…å†µ
                    accumulated_token_usage["model_name"] = self.args.chat_model
                    accumulated_token_usage["input_tokens"] += last_meta.input_tokens_count
                    accumulated_token_usage["output_tokens"] += last_meta.generated_tokens_count

                    printer.print_key_value(accumulated_token_usage)

                elif isinstance(event, WindowLengthChangeEvent):
                    # æ˜¾ç¤ºå½“å‰ä¼šè¯çš„tokenæ•°é‡
                    printer.print_panel(
                        content=f"å½“å‰ä¼šè¯æ€» tokens: {event.tokens_used}", title="Window Length Change", center=True
                    )

                elif isinstance(event, LLMThinkingEvent):
                    # Render thinking within a less prominent style, maybe grey?
                    printer.print_panel(content=f"{event.text}", title="LLM Thinking", center=True)

                elif isinstance(event, LLMOutputEvent):
                    # Print regular LLM output, potentially as markdown if needed later
                    printer.print_panel(
                        content=f"{event.text}", title="LLM Output", center=True
                    )

                elif isinstance(event, ToolCallEvent):
                    # ä¸æ˜¾ç¤º AttemptCompletionTool ç»“æœ
                    if isinstance(event.tool, AttemptCompletionTool):
                        continue

                    tool_name = type(event.tool).__name__
                    # Use the new internationalized display function
                    display_content = self.get_tool_display_message(event.tool)
                    printer.print_panel(content=display_content, title=f"ğŸ› ï¸ å·¥å…·è°ƒç”¨: {tool_name}", center=True)

                elif isinstance(event, ToolResultEvent):
                    # ä¸æ˜¾ç¤º AttemptCompletionTool å’Œ PlanModeRespondTool ç»“æœ
                    if event.tool_name == "AttemptCompletionTool":
                        continue
                    if event.tool_name == "PlanModeRespondTool":
                        continue

                    result = event.result
                    title = f"âœ… å·¥å…·è¿”å›: {event.tool_name}" if result.success else f"âŒ å·¥å…·è¿”å›: {event.tool_name}"
                    border_style = "green" if result.success else "red"
                    base_content = f"çŠ¶æ€: {'æˆåŠŸ' if result.success else 'å¤±è´¥'}\n"
                    base_content += f"ä¿¡æ¯: {result.message}\n"

                    def _format_content(_content):
                        if len(_content) > 500:
                            return f"{_content[:200]}\n......\n{_content[-200:]}"
                        else:
                            return _content

                    # Prepare panel for base info first
                    panel_content = [base_content]
                    # syntax_content = None
                    content_str = ""
                    lexer = "python"  # Default guess

                    if result.content is not None:
                        try:
                            if isinstance(result.content, (dict, list)):
                                content_str = _format_content(json.dumps(result.content, indent=2, ensure_ascii=False))
                                # syntax_content = Syntax(content_str, "json", theme="default", line_numbers=False)
                            elif isinstance(result.content, str) and (
                                    '\n' in result.content or result.content.strip().startswith('<')):
                                # Heuristic for code or XML/HTML
                                if event.tool_name == "ReadFileTool" and isinstance(event.result.message, str):
                                    # Try to guess lexer from file extension in message
                                    if ".py" in event.result.message:
                                        lexer = "python"
                                    elif ".js" in event.result.message:
                                        lexer = "javascript"
                                    elif ".ts" in event.result.message:
                                        lexer = "typescript"
                                    elif ".html" in event.result.message:
                                        lexer = "html"
                                    elif ".css" in event.result.message:
                                        lexer = "css"
                                    elif ".json" in event.result.message:
                                        lexer = "json"
                                    elif ".xml" in event.result.message:
                                        lexer = "xml"
                                    elif ".md" in event.result.message:
                                        lexer = "markdown"
                                    else:
                                        lexer = "text"  # Fallback lexer
                                elif event.tool_name == "ExecuteCommandTool":
                                    lexer = "shell"
                                else:
                                    lexer = "text"

                                content_str = _format_content(str(result.content))
                                # syntax_content = Syntax(
                                #     _format_content(result.content), lexer, theme="default", line_numbers=True
                                # )
                            else:
                                content_str = str(result.content)
                                # Append simple string content directly
                                panel_content.append(_format_content(content_str))

                        except Exception as e:
                            printer.print_text(f"Error formatting tool result content: {e}", style="yellow")
                            panel_content.append(
                                # Fallback
                                _format_content(str(result.content)))

                    # Print the base info panel
                    printer.print_panel(
                        content="\n".join(panel_content), title=title, border_style=border_style, center=True)
                    # Print syntax highlighted content separately if it exists
                    if content_str:
                        printer.print_code(
                            code=content_str, lexer=lexer, theme="monokai", line_numbers=True, panel=True)

                elif isinstance(event, PlanModeRespondEvent):
                    printer.print_panel(
                        content=Markdown(event.completion.response),
                        title="ğŸ ä»»åŠ¡å®Œæˆ", center=True
                    )

                elif isinstance(event, CompletionEvent):
                    # åœ¨è¿™é‡Œå®Œæˆå®é™…åˆå¹¶
                    # Ask æ¨¡å¼ä¸ä¼šå¯¹ä»£ç è¿›è¡Œå˜æ›´,æ•…æ”¾å¼ƒåˆå¹¶
                    # try:
                    #     self.apply_changes(request)
                    # except Exception as e:
                    #     printer.print_text(f"Error merging shadow changes to project: {e}", style="red")

                    printer.print_panel(
                        content=Markdown(event.completion.result),
                        title="ğŸ ä»»åŠ¡å®Œæˆ", center=True
                    )
                    if event.completion.command:
                        printer.print_text(f"Suggested command:{event.completion.command}", style="green")

                elif isinstance(event, ErrorEvent):
                    printer.print_panel(
                        content=f"Error: {event.message}",
                        title="ğŸ”¥ ä»»åŠ¡å¤±è´¥", center=True
                    )

                time.sleep(self.args.anti_quota_limit)  # Small delay for better visual flow

            # åœ¨å¤„ç†å®Œæ‰€æœ‰äº‹ä»¶åæ‰“å°ç´¯è®¡çš„tokenä½¿ç”¨æƒ…å†µ
            printer.print_key_value(accumulated_token_usage)

        except Exception as err:
            # åœ¨å¤„ç†å¼‚å¸¸æ—¶ä¹Ÿæ‰“å°ç´¯è®¡çš„tokenä½¿ç”¨æƒ…å†µ
            if accumulated_token_usage["input_tokens"] > 0:
                printer.print_key_value(accumulated_token_usage)
            printer.print_panel(content=f"FATAL ERROR: {err}", title="ğŸ”¥ Agentic Report è¿è¡Œé”™è¯¯", center=True)
            raise err

        printer.print_text("Agentic Report ç»“æŸ", style="green")